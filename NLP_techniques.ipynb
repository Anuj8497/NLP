{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words approach: Takes in all the text, selects the unique words and then creates a vector out of it.\n",
    "### Application: Document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = ['I love the book', 'this is a great book', 'the fit is great', 'I love the shoes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary = True) # binary = true keeps the elements of vectors as 1's and 0's. Otherwise say if ,,\n",
    "# a certain word had appeared twice then the corresponding entry in the vector would have been 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.fit_transform(train_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.toarray() # converting sparse matrix into normal array using toarray() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['book', 'fit', 'great', 'is', 'love', 'shoes', 'the', 'this']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get the set of unique features\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now lets build a simple model that classifies the above sentences into categories books and clothing\n",
    "class Category:\n",
    "    BOOKS = \"BOOKS\"\n",
    "    CLOTHING = \"CLOTHING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating labels for the test cases\n",
    "train_y = [Category.BOOKS, Category.BOOKS,Category.CLOTHING,Category.CLOTHING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best way to classify text is by using linear SVM\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(vectors,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = vectorizer.transform(['I like the book'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BOOKS'], dtype='<U8')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = vectorizer.transform(['cardigans are great'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CLOTHING'], dtype='<U8')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_1.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the above approach is called unigram as its only taking a single word as token\n",
    "# we can also do a bigram approach where it takes two words as a token. this approach is highly useful in sentinment analysis\n",
    "# great might be classified as positve. But what if it was actually 'not great' in the sentence. In such cases bigram approach is good.\n",
    "# vectors = vectorizer.fit_transform(train_x,ngram_range = (1,2)) -> token with one and two words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vectors Approach: It tries to capture the semantic meaning of the words in the vector. How it catches the semantic meaning is by catching the window of text. Say for example ''Best book I've read in years\" -> the word2vec would catch Best book I've read. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz#egg=en_core_web_md==2.3.1 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from en_core_web_md==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.16.4)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.7.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\anuj8\\appdata\\roaming\\python\\python37\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (41.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\anuj8\\appdata\\roaming\\python\\python37\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.7.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.24.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2019.6.16)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\anuj8\\anaconda3\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.5.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(r'C:\\Users\\anuj8\\Anaconda3\\Lib\\site-packages\\en_core_web_md\\en_core_web_md-2.3.1') # md stands for medium sized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(text) for text in train_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[I love the book, this is a great book, the fit is great, I love the shoes]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08563001  0.313255   -0.2392405  -0.17215225  0.1418515   0.1970548\n",
      "  0.04868999 -0.12744625  0.05947001  2.1347     -0.61964     0.01162549\n",
      "  0.29980502 -0.125354    0.017935   -0.1355105  -0.27094752  1.1129825\n",
      " -0.16986902 -0.0266875   0.14768225 -0.16372526  0.121907   -0.06876825\n",
      " -0.061945    0.08704174 -0.2005705  -0.24039775 -0.0675595   0.0926495\n",
      " -0.13526568  0.24121101 -0.20299     0.30007     0.11574501  0.055062\n",
      "  0.013516   -0.0664179  -0.3380587  -0.17823698 -0.01039225  0.03333575\n",
      " -0.10241525 -0.093445    0.09327275  0.20661727 -0.15074751  0.14018372\n",
      "  0.23520125 -0.05192125 -0.0999365  -0.1212635  -0.05895525 -0.005062\n",
      "  0.06003174  0.01213001 -0.11257375 -0.24570274  0.00678    -0.1888345\n",
      " -0.09276348 -0.25614128 -0.20717824  0.0858725  -0.02215025 -0.303222\n",
      " -0.00274375  0.11888     0.02695867  0.20738849  0.02140525 -0.0175935\n",
      "  0.1513575  -0.0032025   0.20425075  0.16609626 -0.084585   -0.0744465\n",
      " -0.1083965   0.14420825  0.13595775  0.2158625   0.15477975 -0.04820438\n",
      "  0.23010999 -0.2999731  -0.126152   -0.42502826  0.17733926  0.08174075\n",
      " -0.26656875 -0.101404   -0.253544    0.05471925  0.2847125   0.09851776\n",
      "  0.204341    0.16268425 -0.042765   -0.1949425   0.10958    -0.3648075\n",
      " -0.09682125 -0.11094925  0.12445608 -0.359581    0.15130275  0.06853426\n",
      " -0.109819   -0.21615925  0.0958285  -0.00383826  0.26055914 -0.35583502\n",
      "  0.0842915  -0.14935926 -0.1996505   0.23104301 -0.0077375  -0.06271806\n",
      "  0.17203225 -0.181445    0.03677999  0.09908225  0.2382695   0.4065215\n",
      " -0.0908625  -0.15399225  0.08435975 -0.053317   -0.20035249 -0.163792\n",
      " -0.271757    0.01030713  0.03340515  0.0497255  -0.13881615  0.084502\n",
      " -0.053755   -0.31270498 -2.257525   -0.1419485   0.14178     0.08852901\n",
      " -0.17659001 -0.13609049 -0.04871     0.09790501 -0.08347125 -0.20770678\n",
      " -0.04589     0.13999274  0.16002081  0.0629995   0.0256235  -0.04082\n",
      " -0.15203801 -0.1771985  -0.217835   -0.039533    0.089236    0.18021\n",
      "  0.015082    0.03417152 -0.07016499 -0.13753426  0.035425   -0.19859773\n",
      "  0.1456615   0.09975475 -0.100101   -0.0668525   0.22425    -0.452075\n",
      "  0.11908074  0.05990475 -0.0488925   0.1621385  -0.101395   -0.1326985\n",
      "  0.069592   -0.16106975 -0.1380995  -0.22239     0.05668125 -0.0171395\n",
      " -0.29649    -0.3353225   0.06168649  0.09971251 -0.15555725 -0.09166402\n",
      " -0.282595   -0.16052501 -0.02805945  0.15195748  0.07515249 -0.27176827\n",
      "  0.05228776  0.00373    -0.130024   -0.22874999 -0.07862875 -0.0399495\n",
      "  0.264615    0.098764    0.0206625   0.05326832 -0.1118725   0.10922225\n",
      "  0.00446974  0.115469   -0.17844    -0.38571697  0.0452885   0.24619749\n",
      " -0.008345   -0.2139215  -0.0598165   0.1438475   0.1524835  -0.08872448\n",
      "  0.07794543 -0.01462124 -0.273732   -0.07258825  0.1016425   0.16666101\n",
      "  0.0239075   0.03709501 -0.267228    0.0838585  -0.10917226  0.07474675\n",
      " -0.2799775  -0.23018251 -0.15760949 -0.02298325 -0.16043949  0.22297475\n",
      "  0.04065251  0.11423799 -0.095754    0.207424    0.12350225 -0.21028924\n",
      " -0.09836699  0.024505   -0.1130115   0.01491502  0.18254225 -0.309755\n",
      " -0.13121249 -0.008149    0.17937374  0.1328375   0.13090524 -0.09056126\n",
      " -0.17138    -0.12233325  0.12965076  0.020424    0.05174625  0.22267\n",
      "  0.26246977 -0.215415    0.13679275  0.2902495   0.25620502  0.0093\n",
      " -0.22721347 -0.26039124 -0.36055002  0.01478199  0.0270805   0.03114517\n",
      " -0.24702299 -0.02437525 -0.03598415  0.22466755  0.0266175  -0.08971775\n",
      " -0.14917499 -0.30266726 -0.05662975  0.0756845   0.35060728  0.1437245\n",
      " -0.0064325  -0.15310623 -0.1476075   0.09711101 -0.09789225 -0.06524446\n",
      "  0.32439575 -0.06215625  0.20532525 -0.040052    0.0630795   0.14291999]\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].vector) # this gives the vector representation of the text 'I love the book'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = [docs[i].vector for i in range(len(docs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0.08563001,  0.313255  , -0.2392405 , -0.17215225,  0.1418515 ,\n",
       "         0.1970548 ,  0.04868999, -0.12744625,  0.05947001,  2.1347    ,\n",
       "        -0.61964   ,  0.01162549,  0.29980502, -0.125354  ,  0.017935  ,\n",
       "        -0.1355105 , -0.27094752,  1.1129825 , -0.16986902, -0.0266875 ,\n",
       "         0.14768225, -0.16372526,  0.121907  , -0.06876825, -0.061945  ,\n",
       "         0.08704174, -0.2005705 , -0.24039775, -0.0675595 ,  0.0926495 ,\n",
       "        -0.13526568,  0.24121101, -0.20299   ,  0.30007   ,  0.11574501,\n",
       "         0.055062  ,  0.013516  , -0.0664179 , -0.3380587 , -0.17823698,\n",
       "        -0.01039225,  0.03333575, -0.10241525, -0.093445  ,  0.09327275,\n",
       "         0.20661727, -0.15074751,  0.14018372,  0.23520125, -0.05192125,\n",
       "        -0.0999365 , -0.1212635 , -0.05895525, -0.005062  ,  0.06003174,\n",
       "         0.01213001, -0.11257375, -0.24570274,  0.00678   , -0.1888345 ,\n",
       "        -0.09276348, -0.25614128, -0.20717824,  0.0858725 , -0.02215025,\n",
       "        -0.303222  , -0.00274375,  0.11888   ,  0.02695867,  0.20738849,\n",
       "         0.02140525, -0.0175935 ,  0.1513575 , -0.0032025 ,  0.20425075,\n",
       "         0.16609626, -0.084585  , -0.0744465 , -0.1083965 ,  0.14420825,\n",
       "         0.13595775,  0.2158625 ,  0.15477975, -0.04820438,  0.23010999,\n",
       "        -0.2999731 , -0.126152  , -0.42502826,  0.17733926,  0.08174075,\n",
       "        -0.26656875, -0.101404  , -0.253544  ,  0.05471925,  0.2847125 ,\n",
       "         0.09851776,  0.204341  ,  0.16268425, -0.042765  , -0.1949425 ,\n",
       "         0.10958   , -0.3648075 , -0.09682125, -0.11094925,  0.12445608,\n",
       "        -0.359581  ,  0.15130275,  0.06853426, -0.109819  , -0.21615925,\n",
       "         0.0958285 , -0.00383826,  0.26055914, -0.35583502,  0.0842915 ,\n",
       "        -0.14935926, -0.1996505 ,  0.23104301, -0.0077375 , -0.06271806,\n",
       "         0.17203225, -0.181445  ,  0.03677999,  0.09908225,  0.2382695 ,\n",
       "         0.4065215 , -0.0908625 , -0.15399225,  0.08435975, -0.053317  ,\n",
       "        -0.20035249, -0.163792  , -0.271757  ,  0.01030713,  0.03340515,\n",
       "         0.0497255 , -0.13881615,  0.084502  , -0.053755  , -0.31270498,\n",
       "        -2.257525  , -0.1419485 ,  0.14178   ,  0.08852901, -0.17659001,\n",
       "        -0.13609049, -0.04871   ,  0.09790501, -0.08347125, -0.20770678,\n",
       "        -0.04589   ,  0.13999274,  0.16002081,  0.0629995 ,  0.0256235 ,\n",
       "        -0.04082   , -0.15203801, -0.1771985 , -0.217835  , -0.039533  ,\n",
       "         0.089236  ,  0.18021   ,  0.015082  ,  0.03417152, -0.07016499,\n",
       "        -0.13753426,  0.035425  , -0.19859773,  0.1456615 ,  0.09975475,\n",
       "        -0.100101  , -0.0668525 ,  0.22425   , -0.452075  ,  0.11908074,\n",
       "         0.05990475, -0.0488925 ,  0.1621385 , -0.101395  , -0.1326985 ,\n",
       "         0.069592  , -0.16106975, -0.1380995 , -0.22239   ,  0.05668125,\n",
       "        -0.0171395 , -0.29649   , -0.3353225 ,  0.06168649,  0.09971251,\n",
       "        -0.15555725, -0.09166402, -0.282595  , -0.16052501, -0.02805945,\n",
       "         0.15195748,  0.07515249, -0.27176827,  0.05228776,  0.00373   ,\n",
       "        -0.130024  , -0.22874999, -0.07862875, -0.0399495 ,  0.264615  ,\n",
       "         0.098764  ,  0.0206625 ,  0.05326832, -0.1118725 ,  0.10922225,\n",
       "         0.00446974,  0.115469  , -0.17844   , -0.38571697,  0.0452885 ,\n",
       "         0.24619749, -0.008345  , -0.2139215 , -0.0598165 ,  0.1438475 ,\n",
       "         0.1524835 , -0.08872448,  0.07794543, -0.01462124, -0.273732  ,\n",
       "        -0.07258825,  0.1016425 ,  0.16666101,  0.0239075 ,  0.03709501,\n",
       "        -0.267228  ,  0.0838585 , -0.10917226,  0.07474675, -0.2799775 ,\n",
       "        -0.23018251, -0.15760949, -0.02298325, -0.16043949,  0.22297475,\n",
       "         0.04065251,  0.11423799, -0.095754  ,  0.207424  ,  0.12350225,\n",
       "        -0.21028924, -0.09836699,  0.024505  , -0.1130115 ,  0.01491502,\n",
       "         0.18254225, -0.309755  , -0.13121249, -0.008149  ,  0.17937374,\n",
       "         0.1328375 ,  0.13090524, -0.09056126, -0.17138   , -0.12233325,\n",
       "         0.12965076,  0.020424  ,  0.05174625,  0.22267   ,  0.26246977,\n",
       "        -0.215415  ,  0.13679275,  0.2902495 ,  0.25620502,  0.0093    ,\n",
       "        -0.22721347, -0.26039124, -0.36055002,  0.01478199,  0.0270805 ,\n",
       "         0.03114517, -0.24702299, -0.02437525, -0.03598415,  0.22466755,\n",
       "         0.0266175 , -0.08971775, -0.14917499, -0.30266726, -0.05662975,\n",
       "         0.0756845 ,  0.35060728,  0.1437245 , -0.0064325 , -0.15310623,\n",
       "        -0.1476075 ,  0.09711101, -0.09789225, -0.06524446,  0.32439575,\n",
       "        -0.06215625,  0.20532525, -0.040052  ,  0.0630795 ,  0.14291999],\n",
       "       dtype=float32),\n",
       " array([-9.57887992e-02,  3.67865801e-01, -3.33485380e-02,  1.04276799e-01,\n",
       "         2.21819997e-01, -4.36060410e-03, -3.89796086e-02, -2.82660991e-01,\n",
       "        -5.40531985e-02,  2.38820004e+00, -3.11826944e-01,  5.27304001e-02,\n",
       "         8.91999621e-03,  2.93643586e-02, -6.28778040e-02, -2.77818114e-01,\n",
       "        -1.25259995e-01,  1.25802004e+00, -6.72372058e-02, -1.32749408e-01,\n",
       "        -6.65012002e-02, -2.92099983e-01,  1.99979991e-02,  3.73874605e-02,\n",
       "         7.54040480e-03,  1.39879599e-01, -2.91368011e-02, -4.51583974e-02,\n",
       "        -1.51600003e-01,  2.45409943e-02, -3.54060228e-03,  1.85362205e-01,\n",
       "         6.76589906e-02, -1.71808004e-02,  1.12920001e-01, -2.23393254e-02,\n",
       "         1.31206900e-01, -1.87520593e-01, -1.64148077e-01, -4.55416024e-01,\n",
       "         1.21105000e-01,  2.94852585e-01,  2.74260044e-02, -2.57180780e-01,\n",
       "         9.72032025e-02,  1.73971608e-01, -1.95166022e-01,  4.66940030e-02,\n",
       "        -3.22400336e-03, -2.12225970e-02, -1.70456797e-01,  2.24013999e-01,\n",
       "         1.04110397e-01,  6.42545968e-02,  1.02592006e-01,  9.83797908e-02,\n",
       "         1.49339825e-01,  1.71904005e-02,  1.29391223e-01, -2.48703033e-01,\n",
       "        -7.88312405e-02, -6.62861913e-02, -1.01254404e-01,  1.99555606e-01,\n",
       "         1.66170195e-01, -3.76458228e-01, -7.14590028e-02,  6.64715990e-02,\n",
       "        -8.82740133e-03,  2.84392595e-01,  9.81441960e-02, -6.22940063e-02,\n",
       "         6.95139989e-02, -1.02909192e-01,  1.04591802e-01, -7.21727982e-02,\n",
       "        -3.85932028e-02, -1.75523996e-01, -3.21429998e-01,  4.23962027e-01,\n",
       "        -3.67024019e-02,  4.37881984e-02,  1.37274414e-01,  9.82772559e-02,\n",
       "         1.54753998e-01, -2.47411609e-01, -4.16088194e-01, -2.03830808e-01,\n",
       "         2.31164008e-01, -9.56200063e-02, -2.03277990e-01,  2.37710834e-01,\n",
       "        -2.01494843e-01,  8.44355971e-02,  1.91682801e-01,  1.54175788e-01,\n",
       "        -3.21165994e-02, -3.11439987e-02,  2.75671989e-01, -5.09978551e-03,\n",
       "        -4.36800113e-03, -2.09690005e-01, -2.99722016e-01, -1.07037202e-01,\n",
       "        -1.67114032e-03, -4.79569614e-01,  1.61859602e-01,  1.40953809e-01,\n",
       "        -4.75024059e-02, -2.31111601e-01,  1.16659999e-01,  2.28508003e-02,\n",
       "         1.30079597e-01, -9.13602125e-04, -1.13507606e-01,  2.06099991e-02,\n",
       "        -2.91103989e-01,  2.95968205e-01,  8.40580016e-02, -7.30463723e-03,\n",
       "         2.50941962e-02, -1.18134998e-01,  6.37409985e-02,  7.86715969e-02,\n",
       "        -5.41843995e-02,  2.15551585e-01, -2.76979983e-01, -3.56043994e-01,\n",
       "         1.36395305e-01, -1.50706604e-01, -1.37147397e-01, -3.15613419e-01,\n",
       "        -4.99461964e-02,  7.62792081e-02, -6.53545856e-02,  2.22302862e-02,\n",
       "        -1.73460707e-01, -6.37515932e-02, -9.73219704e-03, -1.87839001e-01,\n",
       "        -1.50757205e+00,  7.98259825e-02,  3.10361981e-01,  1.63081005e-01,\n",
       "        -4.16425988e-02, -3.74679983e-01,  4.56224009e-02, -1.60039991e-01,\n",
       "         3.05451006e-01,  1.11000035e-02, -3.73693928e-02,  1.06053993e-01,\n",
       "         1.25160664e-01, -5.52664027e-02,  1.43437637e-02,  6.22633994e-02,\n",
       "        -1.18152402e-01, -6.19282015e-02, -1.77813724e-01, -1.84504390e-01,\n",
       "         6.28508031e-02,  7.78770000e-02,  1.02980807e-01, -5.02960104e-03,\n",
       "        -2.52312776e-02, -2.29494005e-01,  7.54059851e-03, -5.56364432e-02,\n",
       "         2.02835411e-01, -9.94339958e-02, -2.85018031e-02,  8.16436037e-02,\n",
       "         3.39445978e-01, -1.88951999e-01, -1.34260625e-01,  5.88146038e-02,\n",
       "         5.22455946e-02,  9.74099990e-03, -7.81071931e-02,  1.10670984e-01,\n",
       "        -3.04254033e-02, -1.25321999e-01, -4.42994013e-02, -2.64792800e-01,\n",
       "         2.47256011e-02, -2.57193506e-01, -2.19571784e-01, -7.85140023e-02,\n",
       "        -6.18367009e-02,  7.71014020e-02, -3.31595987e-01, -2.99814194e-02,\n",
       "        -2.89836973e-01,  2.67382205e-01,  7.07813948e-02,  7.01179951e-02,\n",
       "        -5.45019889e-03, -5.58312014e-02,  2.46615201e-01,  6.37679994e-02,\n",
       "        -5.32104075e-02, -1.98713824e-01, -2.49956608e-01,  8.02680291e-03,\n",
       "         2.01191813e-01,  1.29683197e-01, -6.27006069e-02,  2.63498118e-03,\n",
       "        -9.78600420e-03,  1.04281805e-01, -5.75746000e-02,  3.77594009e-02,\n",
       "        -4.86060092e-03, -4.27335978e-01,  1.40071198e-01,  3.66546005e-01,\n",
       "         1.05931997e-01,  1.25373587e-01, -9.69751999e-02, -3.00389975e-02,\n",
       "         2.93558352e-02, -1.48723602e-01,  6.40110001e-02,  1.83989599e-01,\n",
       "         9.85686034e-02, -2.75238007e-01, -8.68945941e-02,  2.67326772e-01,\n",
       "        -6.03785999e-02,  1.18738197e-01, -9.83906016e-02,  2.19677597e-01,\n",
       "        -9.88210067e-02,  5.04942015e-02, -1.67521223e-01, -1.86582893e-01,\n",
       "        -4.77548987e-02, -1.03935398e-01, -2.50716835e-01,  2.02438205e-01,\n",
       "         5.26099987e-02,  5.91742024e-02, -3.28357928e-02,  1.69830203e-01,\n",
       "         2.63010800e-01, -7.42122084e-02, -6.61635995e-02, -1.66886002e-01,\n",
       "        -3.56025994e-02, -1.15874007e-01,  8.08437988e-02, -2.91406989e-01,\n",
       "         1.08246058e-02,  7.90230036e-02, -1.80986039e-02,  1.33209795e-01,\n",
       "         3.54167998e-01, -2.40714997e-01, -7.78530240e-02,  4.04580012e-02,\n",
       "         2.17878193e-01,  9.60812122e-02,  1.23153605e-01,  1.17832206e-01,\n",
       "         2.05605224e-01, -1.09132603e-01,  1.58736408e-01,  2.50927120e-01,\n",
       "         4.22289997e-01,  2.19496191e-02, -6.88986033e-02, -1.37627602e-01,\n",
       "        -2.13939220e-01, -2.78115988e-01, -1.53813601e-01, -1.91480014e-02,\n",
       "        -1.28179997e-01, -2.98100002e-02,  8.29835981e-02,  1.44154251e-01,\n",
       "         1.55574605e-01,  3.79716046e-02, -1.30335972e-01, -2.03867391e-01,\n",
       "        -1.51920676e-01, -7.10878000e-02,  1.91803187e-01, -4.28395942e-02,\n",
       "         9.67399925e-02, -1.28800601e-01, -1.59946412e-01,  1.33166788e-02,\n",
       "        -1.67252012e-02, -2.92392019e-02,  2.99405009e-01,  2.52307765e-02,\n",
       "         1.30460784e-01, -2.04104811e-01, -7.44203925e-02,  1.16296530e-01],\n",
       "       dtype=float32),\n",
       " array([ 1.14665754e-01,  3.93469989e-01, -1.52269691e-01, -6.62920028e-02,\n",
       "         2.10405499e-01, -9.65051949e-02,  1.30900033e-02, -4.37449999e-02,\n",
       "        -2.75567491e-02,  2.17157507e+00, -1.07800171e-01,  2.37314980e-02,\n",
       "         8.54050070e-02,  1.39062256e-01, -5.83779998e-02, -1.62634999e-01,\n",
       "        -2.07198501e-01,  1.34912515e+00, -1.27463758e-01,  3.95670012e-02,\n",
       "        -2.63854235e-01, -3.00774992e-01,  3.91445011e-02, -1.08872175e-01,\n",
       "        -7.73999840e-04,  9.12367553e-02, -5.30469939e-02,  5.34307510e-02,\n",
       "        -1.88710004e-01,  1.82313502e-01, -4.68834303e-02,  2.00319499e-01,\n",
       "         1.48775000e-02,  1.20869495e-01,  2.07210004e-01, -1.52427495e-01,\n",
       "         7.29922503e-02, -1.27170652e-01, -2.23990560e-01, -2.34652504e-01,\n",
       "         1.21430065e-02,  3.78125012e-01, -2.12752491e-01, -7.01714978e-02,\n",
       "         1.35683253e-01,  4.31044921e-02, -1.65901393e-01,  8.39122385e-03,\n",
       "        -1.18848756e-01,  1.70762494e-01, -3.04344967e-02,  1.67942256e-01,\n",
       "         2.84057558e-02, -5.91525026e-02,  1.05136007e-01,  7.63269961e-02,\n",
       "         8.91686231e-02,  4.47624922e-03,  8.20915028e-02, -1.15412949e-02,\n",
       "         5.64932823e-03, -2.74945498e-01,  7.58895129e-02,  3.68132502e-01,\n",
       "         6.23877458e-02, -3.66989732e-01, -2.09319010e-01,  6.46057427e-02,\n",
       "         2.44650058e-02, -4.45174798e-03,  2.97599956e-02, -6.99860007e-02,\n",
       "         2.06522509e-01,  4.98325005e-02,  5.40557466e-02, -1.01107508e-02,\n",
       "        -3.74367535e-02, -8.85950029e-02, -1.71770245e-01,  2.36664996e-01,\n",
       "         7.05245882e-04,  2.29695231e-01, -4.82899919e-02,  7.44586289e-02,\n",
       "         1.57544807e-01, -2.12121248e-01, -3.54062736e-01,  1.22718513e-01,\n",
       "         2.73281753e-01, -6.30917475e-02, -1.21659748e-01,  1.00053050e-01,\n",
       "        -1.27449498e-01,  2.11722493e-01,  2.75295973e-01, -1.36508495e-01,\n",
       "        -6.42417520e-02, -1.86059758e-01,  1.73530251e-01, -4.60299477e-03,\n",
       "         5.96375018e-02, -2.00239509e-01, -1.14321247e-01,  6.41399994e-03,\n",
       "         1.44374996e-01, -7.02695012e-01,  1.69832736e-01,  9.35314968e-02,\n",
       "         4.79124971e-02, -2.12076008e-01,  2.82350183e-03, -1.93981007e-01,\n",
       "        -4.39574942e-03,  8.09498131e-04, -6.41272515e-02,  3.29849944e-02,\n",
       "        -1.70570761e-01,  9.64727551e-02, -1.77739993e-01,  1.07702538e-02,\n",
       "         6.62849844e-03, -1.14719003e-01, -6.08487539e-02,  8.17952529e-02,\n",
       "        -2.42357515e-02,  1.45457253e-01, -2.81472266e-01, -3.39304984e-01,\n",
       "        -3.32872495e-02, -9.33362544e-02, -5.36657423e-02, -1.07736252e-01,\n",
       "        -9.72544923e-02, -1.35142490e-01,  8.32250342e-03,  1.39562517e-01,\n",
       "        -1.88017279e-01, -9.24225003e-02, -6.16735071e-02, -2.02823013e-01,\n",
       "        -1.41736507e+00,  2.02352941e-01,  2.60609984e-01,  1.48416504e-01,\n",
       "         1.62353501e-01, -3.19946498e-01,  1.09037496e-01, -1.19995005e-01,\n",
       "         2.72554994e-01,  3.51585001e-02, -2.91887522e-01, -7.84702525e-02,\n",
       "         1.07005253e-01, -1.26278996e-01,  2.24539470e-02, -2.56014504e-02,\n",
       "        -1.85717508e-01, -8.30595046e-02, -2.14383900e-01, -1.84452504e-01,\n",
       "         1.00010000e-01,  2.26123765e-01,  7.79337063e-03, -7.04522505e-02,\n",
       "         1.79308146e-01, -3.33732486e-01,  2.26964474e-01, -4.12632488e-02,\n",
       "         1.94899276e-01, -2.26225257e-01, -1.80612504e-02, -3.97154950e-02,\n",
       "         2.07814991e-01, -1.13013744e-01, -1.95853278e-01,  1.19488508e-01,\n",
       "        -1.33905001e-02,  9.78517532e-02, -2.66399956e-03,  1.03737503e-01,\n",
       "         5.41044995e-02, -2.29597494e-01, -2.07442492e-01, -8.86497498e-02,\n",
       "        -1.08224250e-01, -8.70927498e-02, -2.71012485e-01, -9.92317498e-02,\n",
       "         4.53015007e-02,  1.65952250e-01, -2.30052739e-01, -9.63934958e-02,\n",
       "        -2.16987252e-01,  1.02767743e-01,  4.54079919e-03,  1.50757492e-01,\n",
       "        -7.20375031e-03, -4.44632508e-02,  5.20899892e-02,  3.04644972e-01,\n",
       "        -1.18989991e-02,  2.88214758e-02, -8.33082572e-02,  1.71602480e-02,\n",
       "         1.32197678e-01,  1.89888999e-01, -1.11441255e-01,  1.29751861e-04,\n",
       "        -1.81563765e-01,  5.09817526e-02, -1.30235747e-01,  2.72622555e-02,\n",
       "        -6.21257462e-02, -3.10006976e-01,  2.04604983e-01,  3.76082480e-01,\n",
       "         3.69527563e-02,  2.36539990e-02, -1.96693495e-01, -1.00096747e-01,\n",
       "        -4.45020106e-03, -2.90142484e-02, -7.95999542e-03,  1.03366747e-01,\n",
       "         1.73054993e-01, -6.28000125e-03,  1.36237461e-02,  2.08684996e-01,\n",
       "         7.77774975e-02,  1.13581747e-01, -1.43323749e-01,  3.12119983e-02,\n",
       "        -1.45205006e-01,  1.21949494e-01,  2.96817534e-02, -5.72624989e-02,\n",
       "         8.16000253e-03, -2.36237496e-01, -2.40898013e-01,  8.86389986e-02,\n",
       "        -4.98855039e-02,  1.28659993e-01, -5.63132465e-02,  2.17758998e-01,\n",
       "         1.47140741e-01, -9.60900038e-02, -1.01209998e-01, -3.11535001e-01,\n",
       "        -8.21925029e-02,  1.19110003e-01,  4.03094999e-02, -1.09789997e-01,\n",
       "        -9.53324884e-02, -1.15082502e-01, -7.23912492e-02,  2.33889759e-01,\n",
       "         3.20730031e-01,  1.43833742e-01, -2.22450010e-02, -1.04849972e-02,\n",
       "         1.44732505e-01,  1.47035003e-01,  8.98592472e-02, -1.26147494e-01,\n",
       "         8.72927532e-02,  1.94405038e-02,  2.45912448e-02,  2.83735991e-01,\n",
       "         1.97579995e-01,  1.23490028e-01,  1.64324254e-01, -3.94287556e-02,\n",
       "        -2.62834758e-01, -2.62049258e-01, -2.15610996e-01, -1.00700252e-01,\n",
       "         1.42012507e-01,  1.57427743e-01,  8.51764977e-02,  1.86870009e-01,\n",
       "         2.44087011e-01,  1.88031763e-01, -6.10352233e-02,  2.31834985e-02,\n",
       "        -2.30641752e-01, -2.12567255e-01,  1.34854987e-01,  2.40364987e-02,\n",
       "         2.52469987e-01, -1.95072502e-01, -2.64854252e-01,  4.23519760e-02,\n",
       "         3.43042500e-02, -1.31165743e-01,  8.71367529e-02, -1.47352749e-02,\n",
       "         5.32674938e-02, -3.46954986e-02, -5.22855036e-02,  9.44816768e-02],\n",
       "       dtype=float32),\n",
       " array([ 1.59926504e-01,  2.08857000e-01, -1.95642501e-01, -3.79706264e-01,\n",
       "         4.96514998e-02,  2.58564800e-01,  3.91524956e-02, -1.73819989e-01,\n",
       "         1.30671009e-01,  1.84757507e+00, -5.39520025e-01, -3.32965031e-02,\n",
       "         2.59804994e-01, -1.16225034e-02, -5.77370003e-02,  8.91370028e-02,\n",
       "        -3.07947516e-01,  1.24473250e+00, -2.31987521e-01,  1.91937506e-01,\n",
       "         6.65410012e-02, -1.70607761e-01, -7.28355050e-02, -1.02618754e-01,\n",
       "        -2.97154754e-01,  1.63259238e-01, -3.14343005e-01, -2.14182749e-01,\n",
       "         4.42854986e-02,  1.10899746e-01, -2.75317580e-03,  1.98100254e-01,\n",
       "        -2.62785017e-01,  3.64252508e-01, -3.79174910e-02, -1.41787991e-01,\n",
       "         1.07292749e-01, -2.68519640e-01, -1.49763703e-01, -7.62774721e-02,\n",
       "        -7.94947445e-02,  1.46389991e-01, -1.28600240e-01,  8.37559998e-02,\n",
       "         7.37577453e-02,  7.41397589e-02, -3.04890007e-01,  9.23494697e-02,\n",
       "         1.33886248e-01,  3.02902516e-02, -1.72747493e-01, -2.27677505e-02,\n",
       "         3.13265026e-02, -1.48469508e-01,  2.58836746e-01,  3.98000330e-03,\n",
       "        -3.41341257e-01, -1.50375247e-01, -8.12550038e-02, -1.23622000e-01,\n",
       "        -2.00483978e-01, -3.86758745e-01, -1.71379238e-01,  8.13775063e-02,\n",
       "        -8.35652500e-02, -1.83546990e-01, -2.37945002e-02,  9.65625048e-02,\n",
       "         1.08363673e-01, -3.87899578e-03, -3.37049998e-02, -1.37590975e-01,\n",
       "         1.78902507e-01,  7.00542480e-02,  1.30785257e-01,  6.86512589e-02,\n",
       "         6.46324977e-02,  1.02141000e-01,  5.49599528e-03, -1.18656747e-01,\n",
       "         2.07952008e-01,  3.65562499e-01, -1.40225261e-01, -1.78693775e-02,\n",
       "         1.76399946e-02, -1.85706839e-01,  3.02975535e-01, -3.12607586e-02,\n",
       "         1.75911754e-01, -1.48844980e-02, -1.09781250e-01,  3.36285010e-02,\n",
       "        -3.12036514e-01, -1.81927532e-02,  2.17648000e-01, -3.60770002e-02,\n",
       "         2.06845999e-01,  5.74632473e-02, -7.21224993e-02, -2.18632489e-01,\n",
       "         5.20287491e-02, -6.25025034e-02,  4.98312525e-02, -3.57342511e-02,\n",
       "        -1.14310011e-02, -4.40286487e-01,  1.38972506e-01, -6.40264973e-02,\n",
       "        -2.69516498e-01, -2.32499257e-01,  5.42160012e-02, -2.77990758e-01,\n",
       "        -5.34258410e-02, -1.15685008e-01, -1.79034993e-02,  8.17007571e-02,\n",
       "         1.34687006e-01, -1.18159495e-01, -8.22491944e-04, -1.59001261e-01,\n",
       "         1.43552244e-01, -3.41102630e-02, -1.13207504e-01, -9.97227505e-02,\n",
       "         3.67277503e-01,  3.56404006e-01,  8.61499831e-03, -1.02136001e-01,\n",
       "         1.60352245e-01,  2.10404992e-02,  8.47750902e-03, -9.23070014e-02,\n",
       "        -4.83240008e-01, -1.43731862e-01,  4.17876542e-02,  4.05082479e-02,\n",
       "        -2.17190027e-01,  1.20929502e-01, -8.31075013e-02, -2.00444996e-01,\n",
       "        -2.51329994e+00,  5.99847510e-02,  2.37165004e-01, -5.29100001e-03,\n",
       "        -9.63750035e-02,  4.08095047e-02,  3.22899967e-02,  1.67259753e-01,\n",
       "        -1.46032497e-01, -1.60276771e-01, -1.48840010e-01,  2.00552456e-02,\n",
       "         5.76824918e-02, -3.89115028e-02, -3.67522463e-02, -1.10655494e-01,\n",
       "        -3.41407508e-01, -2.63616025e-01, -1.38442501e-01, -1.89819992e-01,\n",
       "        -9.26867574e-02,  3.76150012e-02, -1.42728001e-01,  9.44965258e-02,\n",
       "         7.03424960e-02, -8.39847475e-02,  2.49609992e-01, -5.33773005e-03,\n",
       "         4.39515002e-02,  1.89397246e-01, -3.36867511e-01, -5.41074984e-02,\n",
       "         1.55718252e-01, -3.40222478e-01,  1.83907449e-02,  1.10270008e-02,\n",
       "        -1.26719996e-01,  2.32662261e-01,  2.01124921e-02, -4.45187464e-02,\n",
       "         8.58937427e-02, -1.05973996e-01, -8.91275033e-02, -1.58769995e-01,\n",
       "         1.17825065e-03,  5.38262501e-02, -2.24059999e-01, -1.12754993e-01,\n",
       "         1.70255989e-01,  9.12249982e-02, -2.40522530e-02, -2.52515763e-01,\n",
       "        -1.43440008e-01, -3.96950006e-01,  1.31093055e-01,  2.05513746e-01,\n",
       "         1.25781745e-01, -2.98075020e-01, -8.92687440e-02,  2.03474998e-01,\n",
       "        -3.22225094e-02, -1.19402498e-01,  8.49837437e-02,  1.91673011e-01,\n",
       "         2.37292245e-01,  1.25514001e-01,  9.77500007e-02,  6.31493181e-02,\n",
       "        -1.03275001e-01, -5.16402498e-02, -1.70302540e-02,  4.74670008e-02,\n",
       "        -3.18942487e-01, -3.09974492e-01,  1.38641000e-01,  2.88659990e-01,\n",
       "        -7.02512488e-02, -2.19927996e-01, -1.88499004e-01,  1.42328992e-01,\n",
       "         6.79560006e-02,  1.03063032e-01,  5.32454252e-02, -1.77423254e-01,\n",
       "        -3.50091994e-01, -1.55383259e-01,  1.45687491e-01,  1.81452513e-01,\n",
       "         1.40239999e-01,  7.49775022e-02, -2.23597750e-01,  5.01255020e-02,\n",
       "        -2.68647492e-01,  2.38998502e-01, -2.11410001e-01, -3.78635019e-01,\n",
       "        -1.94480002e-01, -4.74707484e-02, -5.78244887e-02,  3.34864736e-01,\n",
       "        -2.16677487e-01,  1.02503896e-01, -1.10569000e-01,  2.53803998e-01,\n",
       "        -6.81127459e-02, -2.34664991e-01, -5.09982444e-02, -1.53424993e-01,\n",
       "        -2.42236495e-01,  2.35267520e-01,  8.05947483e-02, -1.23849005e-01,\n",
       "        -1.02137990e-01, -7.71740004e-02, -3.82374972e-03,  2.25925013e-01,\n",
       "         1.62325248e-01,  1.55601248e-01, -1.09152496e-01,  6.28337488e-02,\n",
       "         9.47972536e-02,  6.33899868e-03,  1.06515497e-01,  1.41922504e-01,\n",
       "         5.00372499e-02, -3.69250029e-03,  1.82252750e-01,  3.33079517e-01,\n",
       "         4.68100011e-02,  9.19075012e-02, -2.31065959e-01,  1.20766252e-01,\n",
       "        -5.14654994e-01, -9.68050584e-03,  2.17079967e-02, -8.25988203e-02,\n",
       "        -1.84685498e-01,  8.52124989e-02,  7.42863417e-02,  3.04427505e-01,\n",
       "         7.66813233e-02, -6.31582513e-02, -9.44597498e-02,  1.49502456e-02,\n",
       "        -9.99197438e-02, -2.51279995e-02,  2.81179249e-01,  1.24696493e-01,\n",
       "         1.82824992e-02, -3.70156229e-01, -7.76699930e-02,  9.92915109e-02,\n",
       "         2.85527483e-02, -2.86749452e-01,  6.82857484e-02, -1.70175254e-01,\n",
       "         7.62427449e-02,  4.84417528e-02,  4.46309969e-02,  1.88487500e-01],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec = svm.SVC(kernel = 'linear')\n",
    "word2vec.fit(train_vectors,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BOOKS'], dtype='<U8')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.predict([nlp('This is an awesome story').vector]) # this approach is now catching the semantics also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CLOTHING'], dtype='<U8')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.predict([nlp('These earings hurt bro').vector])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example1 : start with ab, any characters in between end with cd\n",
    "import re\n",
    "exp = re.compile(r'^ab\\S*cd$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = ['aabbcd','abcbde','aahghf','abcd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for phrase in phrases:\n",
    "    if re.match(exp,phrase):\n",
    "        count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example 2: check if the text contains eiher read, story, book\n",
    "exp_1 = re.compile(r'read|story|book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Surprise motherfuckers'\n",
    "if re.search(exp_1,text):\n",
    "    print('YES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n"
     ]
    }
   ],
   "source": [
    "test = 'I treaded that history'\n",
    "if re.search(exp_1,test):\n",
    "    print('YES')  # even though the string does not contain the words read,story,book explicitly.It still returns yes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To overcome above drawback, we can use word boundary '\\b'\n",
    "exp_2 = re.compile(r'\\bread | \\bstory | \\bbook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    }
   ],
   "source": [
    "test_ = 'I treaded that history'\n",
    "if re.search(exp_2,test_):\n",
    "    print('YES')\n",
    "else:\n",
    "    print('No')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and Lemmatization - Used for normalizing the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming: books - book , reading - read, stories - stori ( this is where stemming fails. It does not guarantee actual\n",
    "# english word)\n",
    "# Lemmaztization is a better alternative and guarantees actual english word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anuj8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\anuj8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anuj8\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') # examples of stopwords: this, that, the, a ,an etc\n",
    "nltk.download('wordnet') # list of some common words\n",
    "nltk.download('punkt') # it is a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'Reading the books'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = word_tokenize(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read\n",
      "the\n",
      "book\n"
     ]
    }
   ],
   "source": [
    "for items in x:\n",
    "    print(stemmer.stem(items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'I hate love stories'\n",
    "y1 = word_tokenize(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "hate\n",
      "love\n",
      "story\n"
     ]
    }
   ],
   "source": [
    "for items in y1:\n",
    "    print(lemmatizer.lemmatize(items,pos = 'n')) # pos is part of speech tagging and we can add according to our need\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'Here is an example demonstrating removal of stopwords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "for token in tokens:\n",
    "    if token not in words:\n",
    "        clean.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Here', 'example', 'demonstrating', 'removal', 'stopwords']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here example demonstrating removal stopwords'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other(spell correction, sentiment, part of speech tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text on which we are working always need to be passed to TextBlob object\n",
    "phrase = 'this is a very good but bad phrase'\n",
    "tb_phrase = TextBlob(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"this is a very good but bad phrase\")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_phrase.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('very', 'RB'),\n",
       " ('good', 'JJ'),\n",
       " ('but', 'CC'),\n",
       " ('bad', 'JJ'),\n",
       " ('phrase', 'NN')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_phrase.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.10500000000000004, subjectivity=0.7233333333333334)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_phrase.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
